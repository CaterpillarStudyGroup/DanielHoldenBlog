
P2   
## Framework 

![](./assets/lhy2-2-1.png) 

![](./assets/lhy2-2-2.png) 

P3   
## Stable Diffusion 

<https://arxiv.org/abs/2112.10752>  

![](./assets/lhy2-3.png) 

P4   
## DALL-E series 
<https://arxiv.org/abs/2204.06125>

<https://arxiv.org/abs/2102.12092>

![](./assets/lhy2-4.png) 


P5   
## Imagen 

<https://imagen.research.google/>

<https://arxiv.org/abs/2205.11487>


![](./assets/lhy2-5-1.png) 




P7   

![](./assets/lhy2-7-1.png) 

<https://arxiv.org/abs/2205.11487>



P8   
## Fréchet Inception Distance (FID)

<https://arxiv.org/abs/1706.08500>


![](./assets/lhy2-8.png) 

P9   
## Contrastive Language-Image Pre-Training (CLIP) 

<https://arxiv.org/abs/2103.00020>

400 million image-text pairs  


![](./assets/lhy2-9-1.png) 

P10   
## Framework

Decoder can be trained without labelled data.   

Decoder



P11  
## 「中间产物」为小图

![](./assets/lhy2-11-1.png) 

P12   
## 「中间产物」为「Latent Representation」

Auto-encoder

![](./assets/lhy2-12-1.png) 

![](./assets/lhy2-12-2.png) 



P14   
![](./assets/lhy2-14.png) 


P15   
![](./assets/lhy2-15.png) 

P16   
![](./assets/lhy2-16.png) 


P17   
## Stable Diffusion 

<https://arxiv.org/abs/2112.10752>

![](./assets/lhy2-17.png) 


